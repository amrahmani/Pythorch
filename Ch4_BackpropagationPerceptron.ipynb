{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amrahmani/Pythorch/blob/main/Ch4_BackpropagationPerceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write PyTorch code to create a simple perceptron with one neuron, two inputs, and one output. The output should have a ReLU activation function. Suppose we want to train it with the following dataset: [(x = (1, 1), y = 1), (x = (1, 2), y = 2), (x = (1, 3), y = 3), (x = (3, 2), y = 6), (x = (3, 1), y = 3), (x = (2, 2), y = 4), (x = (3, 3), y = 9), (x = (3, 4), y = 12)]. Include the forward pass and backward pass for this neuron for weight adjustment."
      ],
      "metadata": {
        "id": "zB6nyz0p8M7V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fz9wwWetz6Rc",
        "outputId": "d70acef2-c83b-4a31-999f-fb53731958f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted output for new input: tensor([3., 4.]) is 11.366147994995117\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Perceptron(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Perceptron, self).__init__()\n",
        "        self.linear = nn.Linear(2, 1)  # Linear layer with 2 inputs and 1 output\n",
        "        self.relu = nn.ReLU()  # ReLU activation\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Ensure input is of type float\n",
        "        x = x.float()  # Convert input to float if necessary\n",
        "        output = self.linear(x)  # Apply linear transformation\n",
        "        output = self.relu(output)  # Apply ReLU activation\n",
        "        return output\n",
        "\n",
        "# Sample data (replace with actual dataset)\n",
        "data = [\n",
        "    (torch.tensor([1., 1.]), torch.tensor(1.0)),  # Ensure target is float\n",
        "    (torch.tensor([1., 2.]), torch.tensor(2.0)),\n",
        "    (torch.tensor([1., 3.]), torch.tensor(3.0)),\n",
        "    (torch.tensor([3., 2.]), torch.tensor(6.0)),\n",
        "    (torch.tensor([3., 1.]), torch.tensor(3.0)),\n",
        "    (torch.tensor([2., 2.]), torch.tensor(4.0)),\n",
        "    (torch.tensor([3., 3.]), torch.tensor(9.0)),\n",
        "    (torch.tensor([3., 4.]), torch.tensor(12.0)),\n",
        "]\n",
        "\n",
        "# Create model and optimizer\n",
        "model = Perceptron()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)  # SGD with learning rate 0.01\n",
        "criterion = nn.MSELoss()  # Instantiate the loss function\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(100):  # Adjust number of epochs as needed\n",
        "    for x, y in data:\n",
        "        # Forward pass\n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, y)  # Mean Squared Error loss\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()   # Resets gradients of the model's parameters to zero for efficient backpropagation\n",
        "        loss.backward()   # Propagats the errors back through the network and update the weights of the neurons\n",
        "        optimizer.step()   # Updates the model's weights based on the calculated gradients\n",
        "\n",
        "\n",
        "# Prediction on a new input (example)\n",
        "new_x = torch.tensor([3, 4]).float()\n",
        "predicted_y = model(new_x)\n",
        "print('Predicted output for new input:', new_x, 'is', predicted_y.item())\n"
      ]
    }
  ]
}