{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amrahmani/Pythorch/blob/main/ANeuronLearnMultiplyInput.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a single-neuron perceptron with a bias and 3 inputs in PyTorch. The neuron will utilize the ReLU activation function. This implementation will train the neuron based on the delta rule with the formula: ùëä_ùëõùëíùë§ = ùëä_ùëúùëôùëë + ùõº(ùë¶ - ùë¶_hat), where 'y' represents the desired output and 'y_hat' represents the predicted output. The goal is to train the neuron for the product of 3 integer inputs between 1 and 5. We will create 20 training input-output pairs for this purpose."
      ],
      "metadata": {
        "id": "A5owvG6E6h2m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDilAgiZyMQT",
        "outputId": "7d99b04d-43f0-4ba8-90cb-ab7d4fe03b5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training_data =  [(tensor([3., 1., 2.]), tensor(6.)), (tensor([3., 1., 1.]), tensor(3.)), (tensor([5., 3., 3.]), tensor(45.)), (tensor([2., 2., 4.]), tensor(16.)), (tensor([4., 4., 5.]), tensor(80.)), (tensor([3., 1., 4.]), tensor(12.)), (tensor([2., 3., 2.]), tensor(12.)), (tensor([5., 2., 1.]), tensor(10.)), (tensor([3., 5., 2.]), tensor(30.)), (tensor([4., 4., 1.]), tensor(16.)), (tensor([3., 3., 5.]), tensor(45.)), (tensor([1., 3., 5.]), tensor(15.)), (tensor([2., 2., 5.]), tensor(20.)), (tensor([1., 5., 2.]), tensor(10.)), (tensor([3., 5., 2.]), tensor(30.)), (tensor([3., 5., 5.]), tensor(75.)), (tensor([3., 5., 5.]), tensor(75.)), (tensor([3., 3., 4.]), tensor(36.)), (tensor([5., 1., 2.]), tensor(10.)), (tensor([3., 1., 2.]), tensor(6.))]\n",
            "Epoch [1/1000], Loss: 17.4074\n",
            "Epoch [101/1000], Loss: 3.8825\n",
            "Epoch [201/1000], Loss: 6.0000\n",
            "Epoch [301/1000], Loss: 6.0000\n",
            "Epoch [401/1000], Loss: 6.0000\n",
            "Epoch [501/1000], Loss: 6.0000\n",
            "Epoch [601/1000], Loss: 6.0000\n",
            "Epoch [701/1000], Loss: 6.0000\n",
            "Epoch [801/1000], Loss: 6.0000\n",
            "Epoch [901/1000], Loss: 6.0000\n",
            "Predicted output for tensor([2., 3., 4.]): 27.648948669433594\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import random\n",
        "\n",
        "# Define the neuron class\n",
        "class SingleNeuron(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SingleNeuron, self).__init__()\n",
        "        # Initialize weights and bias randomly\n",
        "        self.weights = torch.randn(3)\n",
        "        self.bias = torch.randn(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Define the forward pass using ReLU activation function\n",
        "        y_hat = torch.relu(torch.sum(x * self.weights) + self.bias)\n",
        "        return y_hat\n",
        "\n",
        "# Define training parameters\n",
        "learning_rate = 0.01\n",
        "alpha = 0.01  # learning rate for delta rule\n",
        "num_epochs = 1000\n",
        "\n",
        "# Create training data\n",
        "training_data = []\n",
        "for _ in range(20):\n",
        "    # Generate random inputs between 1 and 5\n",
        "    x = torch.tensor([random.randint(1, 5), random.randint(1, 5), random.randint(1, 5)], dtype=torch.float32)\n",
        "    # Calculate the output as the product of inputs\n",
        "    y = torch.prod(x)\n",
        "    training_data.append((x, y))\n",
        "\n",
        "print(\"training_data = \", training_data)\n",
        "# Create the neuron\n",
        "neuron = SingleNeuron()\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Iterate through each training example\n",
        "    for x, y in training_data:\n",
        "        # Forward pass\n",
        "        y_hat = neuron(x)\n",
        "        # Compute the loss\n",
        "        loss = torch.abs(y - y_hat)\n",
        "        # Update weights and bias\n",
        "        neuron.weights.data = neuron.weights.data + (alpha * (y - y_hat) * x)\n",
        "        neuron.bias.data = neuron.bias.data + (alpha * (y - y_hat))\n",
        "\n",
        "    # Print loss every 100 epochs\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Test the trained neuron\n",
        "test_input = torch.tensor([2, 3, 4], dtype=torch.float32)\n",
        "predicted_output = neuron(test_input)\n",
        "print(f'Predicted output for {test_input}: {predicted_output.item()}')\n"
      ]
    }
  ]
}
